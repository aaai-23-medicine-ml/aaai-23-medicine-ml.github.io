<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
        "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">

<head>
  <title> AAAI-23 Bridge Program:  </title>
  Bridge between Medicine and Machine Learning.
  <meta name="robots" content="index,follow" />
  <link rel="stylesheet" type="text/css" href="fonts.css" />
  <link rel="stylesheet" type="text/css" href="style.css" />
  <script src="jquery.js"></script>
  <script src="bootstrap.min.js"></script>
</head>

<body data-spy="scroll" data-target=".navbar" id="about">
<div class='content'>

    <div class='title'>
      <a href="index.html"><strong>AAAI-23 Bridge Program: <br/></strong> 
         Bridge between Medicine and Machine Learning </a>
    </div>

    <div class="band">
    <a class="band" class="thumb"><img src=imgs/brain_mri.png></a>
    <a class="band" class="thumb"><img src=imgs/chest-x-rays.png></a>
    <a class="band" class="thumb"><img src=imgs/scanner.png></a>
    <a class="band" class="thumb"><img src=imgs/ct.png></a>
    </div>


<div class='article'>


<h2 id="schedule">Speakers </h2>


<b> Uncertainty, Interpretability, and Explainability: Critical Components for the Safe Implementation and Integration of AI into Clinical Medicine </b> <br>

Dan Nguyen
Assistant Professor </br>
Department of Radiation Oncology</br>
UT Southwestern </br>
</br>
Abstract: </br>
In the last decade, artificial intelligence (AI) technology has boomed, finding its way in every facet of every field, from home goods to automobiles. In particular, it is finding its way into medical applications as well, disrupting the way we think approach and think about patient service and care. However, the complexity of state-of-the-art AI methods, namely deep learning (DL), which allows for its unparalleled performance, is a double-edged sword that also makes it difficult to understand several aspects of its decision making. Its black box nature makes it dangerous for medical applications, as an incorrect prediction can negatively impact a patient’s outcome and quality of life. Much research in the last few years has begun to tackle several aspects—uncertainty, interpretability, and explainability—to make the clinical implementation of these AI models safer, more efficient, and trustworthy in the clinic. In this talk we will discuss the current methods and developments in these aforementioned aspects, and their impact for the usage and integration of AI into clinical medicine.
</br>

Bio:</br>
Dan Nguyen, Ph.D., is a scientist with expertise in radiation therapy treatment planning, deep learning, and optimization techniques and algorithms. He completed his Ph.D. in Biomedical Physics in 2017 at the University of California Los Angeles (UCLA), where he worked extensively on 4π Radiotherapy, Fluence Map Optimization, and Direct Aperture Optimization techniques under the guidance and mentorship of Dr. Ke Sheng.
Dan was recruited to the Division of Medical Physics and Engineering, Department of Radiation Oncology at UT Southwestern in 2017 as a faculty member. He was a founding member of the multiple-investigator lab called the Medical Artificial Intelligence and Automation (MAIA) Laboratory, which was focused to innovate, develop, and apply artificial intelligence technologies to empower clinicians—especially those with less experience or limited resources—for improved patient care. He works very closely with Dr. Steve Jiang in researching and applying deep learning technologies to various facets of radiotherapy, including treatment planning, medical imaging, and outcome prediction.




</div> <!-- end of div article -->

</div> <!-- end of div content -->

</body>

</html>

